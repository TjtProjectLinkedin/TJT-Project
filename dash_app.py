#Important library imports
import os, random, sys, time
from urllib.parse import urlparse
from selenium import webdriver
import pandas as pd
import numpy as np
import streamlit as st
from time import time as t1
import unicodecsv as csv
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords

#Returns all the features from static file vocab.txt
def obtain_features():
    # import stop words set from NLTK package
    stop_word_set = set(stopwords.words('english'))

    #Reads vocab.txt and return list of vocab
    with open('vocab.txt',str('rb')) as source:
        rdr = csv.reader(source, encoding='utf-8')
        features = []
        skill_set = set()
        for row in rdr:
            skill = row[0].lower()
            if skill not in skill_set and skill not in stop_word_set:
                skill_set.add(skill)
                features.append(skill)
    return features

#Returns all the possible features extracted from job description
def NMF_cluster(data, min_n, max_n, vocab):
    temp_skills = []

    # n_features = len(vocab)
    n_features = 1000

    # Use tf-idf features for NMF.
    tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1,
                                       #vocabulary=vocab,
                                       stop_words='english',
                                       #stop_words=None,
                                       token_pattern=r"(?u)\S+",
                                       max_features=n_features, sublinear_tf=True,
                                       ngram_range=(min_n, max_n))
    tfidf = tfidf_vectorizer.fit_transform(data)

    # print out features generated by tf-idf vectorizer
    feature = tfidf_vectorizer.get_feature_names()
    for each in feature:
        temp_skills.append(each)
    return temp_skills

#Returns all the filtered skills      
def filter_skills(temp_skills):

    #removes single and double word features
    threewordskills = [word for word in temp_skills if len(word.split(' ')) > 2]

    #removes words has specific symbols
    nopuncskills = [word for word in threewordskills if ',' not in word and '.' not in word and '+' not in word]

    #removes words has specific unrelated words
    unrelatedwordsskills = [word for word in nopuncskills if 'like' not in word and 'owner' not in word]

    #sorts features by vocabulary
    sortedbyvocab = []
    for word in unrelatedwordsskills:
        for i in vocab:
            if i in word and word not in sortedbyvocab:
                sortedbyvocab.append(word)

    #creates list of keywords based on keyword and function
    keywords = keyword.split(',')
    functions = function.split(' ')
    keywords.extend(functions)

    #filter skills based on keywords
    skills = [word for word in sortedbyvocab if 'skills' in word.split()[2]]
    for word in sortedbyvocab:
        for i in keywords:
            if i.lower() in word and word not in skills:
                skills.append(word)
                keywords.remove(i)
    return skills

st.title('Top Job Turbo')

#Creates dataframe of excel file of job descriptions
df1 = pd.DataFrame(pd.read_excel('TJT_datasets.xlsx'))

#Creates empty dataframe like above
df = pd.DataFrame(index=[0], columns=df1.columns)

#Takes input from user as job id
jobid = st.text_input("Enter Job ID:")

#Checks for button click
if st.button('Proceed'):

    st.title('Job Description')

    #Get the whole data of job id given by user and store in new dataframe
    try:
        for i in range(len(df1)):
            if int(jobid) == df1['JID'][i]:
                for j in range(8):
                    df[df1.columns[j]][0] = df1[df1.columns[j]][i]
    except:
        pass
    
    #Display job id selected dataframe
    st.dataframe(df)

    #Stores job description, keywords and function
    desc = df['Jdesc'][0]
    keyword = df['Jkeywords'][0]
    function = df['Jfunction'][0]

    #Get all features from vocab file
    vocab = obtain_features()

    #Get all the features extracted by passed job description
    temp_skills = NMF_cluster([desc], 1, 3, vocab)

    #Get filtered list of skills
    skills = filter_skills(temp_skills)

    #Display title and list of skills
    st.title('Skills Required')
    st.write(skills)

    #Creates new empty dataframe to store parsed job description
    step2a_df = pd.DataFrame(index=[0],columns=['Company Name', 'Job Location', 'Headquarter', 'Company Details', 'Job Title', 'Roles', 'Skills', 'PHM'])

    #Parse the job description
    for i in df:
        if 'company' in i:
            step2a_df['Company Name'][0] = df[i][0]
        if 'location' in i:
            step2a_df['Job Location'][0] = df[i][0]
        if 'role' in i or 'function' in i:
            step2a_df['Roles'][0] = df[i][0]
        if 'position' in i or 'title' in i:
            step2a_df['Job Title'][0] = df[i][0]

    #Stores list of filtered skills in dataframe
    step2a_df['Skills'][0] = ', '.join(skills)
    
    #Selenium
    #Get driver
    browser = webdriver.Chrome('driver/chromedriver.exe')

    #Read email and pass from config.txt and login
    file = open('config.txt')
    lines = file.readlines()
    username = lines[0]
    password = lines[1]
    browser.get('https://www.linkedin.com/uas/login')
    elementID = browser.find_element_by_id('username')
    elementID.send_keys(username)
    elementID = browser.find_element_by_id('password')
    elementID.send_keys(password)
    elementID.submit()

    #Search by company name given in job description
    company_name = df['Jcompany'][0]
    fullLink = 'https://www.linkedin.com/search/results/companies/?keywords='+company_name
    browser.get(fullLink)
    element = browser.find_element_by_link_text(company_name)
    element.click()
    time.sleep(5)
    browser.execute_script("window.scrollTo(0, 500)")
    element = browser.find_element_by_link_text("See all")
    element.click()
    time.sleep(5)
    browser.execute_script("window.scrollTo(0, 100)")

    #Grabs company details and headquarters and stores in dataframe
    try:
        company_details = browser.find_element_by_class_name('break-words').text
        st.title("Company Details")
        st.write(company_details)
        step2a_df['Company Details']= company_details
        company_headquarters = browser.find_element_by_class_name('mb3').find_element_by_class_name('overflow-hidden').find_element_by_xpath('(//dd[5])').text
        st.title("Company Headquarters")
        st.write(company_headquarters)
        step2a_df['Headquarter']=company_headquarters
    except:
        pass

    #Reads static PHM file compares the job positions and gets corresponding potential hiring manager
    PHM = pd.DataFrame(pd.read_csv('PHM.csv'))
    for i in range(len(PHM['Interviewee'])):
        if PHM['Interviewee'][i] == step2a_df['Job Title'][0]:
            step2a_df['PHM'][0]=PHM['Hiring Manager'][i]

    #Display title and parsed job description dataframe
    st.title('Job Details')
    st.dataframe(step2a_df)

    #Returns string to create url
    def check_empty(data):
        if data == '':
            return ''
        else:
            return str(data) + '%2C'

    #Stores all the parameter for url like PHM, location, domain 
    PHM = step2a_df['PHM'][0]
    location = step2a_df['Job Location'][0]
    domain = step2a_df['Roles'][0]

    #Creates url based on filters and visits
    temp_url = check_empty(PHM) + check_empty(location) + check_empty(domain)
    fullLink = browser.current_url[:-6] + '/people/?keywords=' +  temp_url[:-3]
    browser.get(fullLink)

    #Creates empty dataframe for storing PHMs profile    
    PHM_df = pd.DataFrame(index=[i for i in range(10)],columns=['Employee Name', 'Job Title', 'Job Location', 'About'])
    current_url = browser.current_url

    #Fetch top 10 profiles of PHMs based onn filters
    for i in range(1,11):
        try:
            #Visits each profile
            browser.find_element_by_class_name('org-people-profiles-module__profile-list').find_element_by_xpath('(//li[@class="org-people-profiles-module__profile-item"]['+str(i)+'])').find_element_by_class_name('org-people-profile-card__profile-info').click()
            time.sleep(3)

            #Fetch PHM's name
            PHM_df['Employee Name'][i-1] = browser.find_element_by_class_name('pv-top-card--list').find_element_by_tag_name('li').text

            #Fetch PHM's job title
            PHM_df['Job Title'][i-1] = browser.find_element_by_class_name('ph5').find_element_by_class_name('mt2').find_element_by_class_name('mt1').text

            #Fetch PHM's job location
            loc = browser.find_element_by_class_name('pv-top-card--list-bullet').find_element_by_tag_name('li').text
            if "connection" in loc:
                PHM_df['Job Location'][i-1] = np.nan
            else:
                PHM_df['Job Location'][i-1] = loc

            #Fetch PHM's about info 
            PHM_df['About'][i-1] = browser.find_element_by_class_name('pv-about__summary-text').text
        except:
            pass
        browser.get(current_url)

    #Drops all the nan profiles
    PHM_df=PHM_df.dropna(how='all')
    PHM_df = PHM_df.reset_index(drop=True)

    #Creates empty dataframe for scores
    scores_df = pd.DataFrame({'scores':[0] * len(PHM_df)})

    #Display all the fetched PHM's profile
    st.title("Potential Hiring Managers Details")
    st.dataframe(PHM_df)

    #Calculates Scores and stores in dataframe
    #In if statement it check for nan, if it has null it assign score as 1
    #In elif statement it checks for words like hire and compares location and job title, if it has such words it assign score as 3
    #If comes in else statement means it has some value and not null, it assign acores as 2
    for i in range(len(PHM_df)):
        #Scoring based on About Section
        if str(np.nan) in str(PHM_df['About'][i]):
            scores_df['scores'][i] = 1
        elif 'hiring' or 'hire' or 'recruiting' or 'recruitment' in str(PHM_df['About'][i]):
            scores_df['scores'][i] = 3
        else:
            scores_df['scores'][i] = 2

        #Scoring based on Location
        if str(np.nan) in str(PHM_df['Job Location'][i]):
            scores_df['scores'][i] += 1
        elif 'chennai' in str(PHM_df['Job Location'][i]).lower(): #take chennai from dataframe on employee use split(',')[0] to take only chennai
            scores_df['scores'][i] += 3
        else:
            scores_df['scores'][i] += 2

        #Scoring based on domain
        if str(np.nan) in str(PHM_df['Job Title'][i]):
            scores_df['scores'][i] += 1
        elif 'Product Management' in str(PHM_df['Job Title'][i]): #take prodcut management from dataframe on employee
            scores_df['scores'][i] += 3
        else:
            scores_df['scores'][i] += 2

    #Gets top 3 PHM's
    top3 = scores_df.index.values[:3]

    #Creates empty dataframe
    top3_df = pd.DataFrame(columns=['Employee Name', 'Job Title', 'Job Location', 'About'])

    #Append all the data of 3 PHM's to dataframe
    for i in range(len(top3)):
        top3_df  = top3_df.append(PHM_df.iloc[top3[i]])

    #Resets index
    top3_df = top3_df.reset_index(drop=True)

    #Display top 3 PHM's profile
    st.title('Top 3 Potential Hiring Manager')
    st.dataframe(top3_df)
